{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06495ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL IMPORTS\n",
    "\n",
    "import importlib\n",
    "import romanizer\n",
    "import db\n",
    "\n",
    "importlib.reload(romanizer)     # Reload romanizer from korean\n",
    "importlib.reload(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL DOWNLOAD\n",
    "\n",
    "import stanza\n",
    "\n",
    "language = 'ko'\n",
    "stanza.download(language)       # Download model\n",
    "nlp = stanza.Pipeline(language) # Initialize neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from psycopg2.extensions import connection\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "conn: connection = db.connect(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE CREATION\n",
    "\n",
    "db.create_tables(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHRASE TOKENIZATION\n",
    "phrase = \"2000년 11월 17일이 바로 그런 날이었어요\"\n",
    "\n",
    "doc = nlp(phrase)\n",
    "dict = doc.to_dict()\n",
    "\n",
    "print(doc.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from color import blue, bold, cyan, green, purple, red\n",
    "\n",
    "\n",
    "for sentences in dict:\n",
    "    print(\"Phrase: \", phrase, '|', blue(romanizer.romanize(phrase)))\n",
    "    for words in sentences:\n",
    "        print(bold(cyan(\"Text: \")), words['text'], '|', blue(romanizer.romanize(words['text'])))\n",
    "\n",
    "        upos = db.get_upos(conn, words['upos'])\n",
    "        print(green(\"Part of Speech: \"), upos)\n",
    "\n",
    "        print(red(\"Morphemes: \"))\n",
    "        morphemes = words['lemma'].split('+')\n",
    "\n",
    "        tags = words['xpos'].split('+')\n",
    "        xpos = db.get_xpos_labels(conn, tags)\n",
    "\n",
    "        morphemes_info = []\n",
    "        for morpheme, tag, xpos_label in zip (morphemes, tags, xpos):\n",
    "            info = db.get_morpheme(conn, morpheme, tag)\n",
    "            morphemes_info.append(info)\n",
    "            print(f\"    '{morpheme}': '{tag} => {xpos_label.title()}' | {bold(red('Translation'))}: {info['translation']}\")\n",
    "\n",
    "\n",
    "\n",
    "        # for morpheme, tag, xpos_label, info in zip(morphemes, tags, xpos, morphemes_info):\n",
    "        #     print(f\"    '{morpheme}': '{tag} => {xpos_label.title()}' | {bold(red('Translation'))}: {info['translation']}\")\n",
    "\n",
    "        translation = db.get_translation(conn, words['text'], words['upos'], morphemes_info)\n",
    "        print(purple(\"Translation: \"), translation)\n",
    "        print(\"─\"*30, '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
